{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3a0dc6",
   "metadata": {},
   "source": [
    "# Project 2 – Group 34\n",
    "## Dataset: Heart Failure Clinical Records\n",
    "**Source:** [UCI Machine Learning Repository](https://doi.org/10.24432/C5Z89R)\n",
    " \n",
    "> This dataset contains the medical records of 299 patients who experienced heart failure, collected during their follow-up period. Each patient profile includes 13 clinical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a40b50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_theme(font_scale=1.)\n",
    "\n",
    "# transformationer\n",
    "def identity(x): return x\n",
    "def log(x): return np.log(x + 1e-6)   # undgå log(0)\n",
    "def sqrt(x): return np.sqrt(np.clip(x, 0, None))  # sqrt kræver >=0\n",
    "def cbrt(x): return np.cbrt(x)        # kan håndtere negative\n",
    "def reciprocal(x): return 1.0 / (x + 1e-6)  # undgå /0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149a750",
   "metadata": {},
   "source": [
    "## Classification: Baseline, Logistic Regression, and KNN\n",
    "We will compare three classification methods on the heart failure dataset:\n",
    "- Baseline (majority class)\n",
    "- Logistic Regression (with regularization)\n",
    "- k-Nearest Neighbors (KNN)\n",
    "Performance will be evaluated using accuracy and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856b8b3",
   "metadata": {},
   "source": [
    "Loading and cleaning the dataset from the outcome of hand_in 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3825d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../02452_Group34_Project1/data/heart_failure_clinical_records_dataset.csv')\n",
    "\n",
    "X = df.drop(columns=['DEATH_EVENT', 'time'])         # Features without target and time\n",
    "y = pd.Categorical(df['DEATH_EVENT'])        # Target as categorical\n",
    "\n",
    "# Check the shape of the data\n",
    "N, M = X.shape\n",
    "assert N == 299, \"There should be 299 samples in the Heart Failure dataset.\"\n",
    "assert M == 11, \"There should be 11 features in the Heart Failure dataset(13 together - target - time)\"\n",
    "\n",
    "#Transform the chosen features \n",
    "X_transformed = X.copy()\n",
    "X_transformed['creatinine_phosphokinase'] = log(X_transformed['creatinine_phosphokinase'])\n",
    "X_transformed['platelets'] = sqrt(X_transformed['platelets'])\n",
    "X_transformed['serum_creatinine'] = reciprocal(X_transformed['serum_creatinine'])\n",
    "\n",
    "X = X_transformed\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "X = X_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57220f46",
   "metadata": {},
   "source": [
    "### 1. Classification Problem Statement\n",
    "We are solving a **binary classification problem**: predicting whether a patient died during the follow-up period (`DEATH_EVENT` = 1) or survived (`DEATH_EVENT` = 0). The target variable is binary, so this is not a multi-class problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "248247bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (majority class): 0.679\n",
      "Logistic Regression CV accuracy: 0.736 ± 0.069\n",
      "KNN (k=5) CV accuracy: 0.676 ± 0.034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Baseline: predict the majority class\n",
    "def baseline_accuracy(y):\n",
    "    majority_class = y.value_counts().idxmax()\n",
    "    y_pred_baseline = np.full_like(y, majority_class)\n",
    "    return accuracy_score(y, y_pred_baseline)\n",
    "\n",
    "baseline_acc = baseline_accuracy(y)\n",
    "print(f'Baseline accuracy (majority class): {baseline_acc:.3f}')\n",
    "\n",
    "# Logistic Regression with regularization (lambda = C^-1)\n",
    "logreg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', max_iter=1000)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=cv, scoring='accuracy')\n",
    "print(f'Logistic Regression CV accuracy: {logreg_scores.mean():.3f} ± {logreg_scores.std():.3f}')\n",
    "\n",
    "# KNN classification (k=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
    "print(f'KNN (k=5) CV accuracy: {knn_scores.mean():.3f} ± {knn_scores.std():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340062b0",
   "metadata": {},
   "source": [
    "### 2. Models and Complexity Parameters\n",
    "- **Logistic Regression**: We use the regularization parameter λ (lambda) to control model complexity. In scikit-learn, this is set via `C = 1/λ`. We will test values such as λ ∈ {0.01, 0.05, 0.1, 0.5, 1.0} (i.e., C ∈ {100, 20, 10, 2, 1}).\n",
    "- **Method 2 (KNN)**: The complexity parameter is the number of neighbors, k. We will test k ∈ {1, 3, 5, 7, 9}.\n",
    "- **Baseline**: Always predicts the majority class in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea510383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Best k</th>\n",
       "      <th>KNN Error</th>\n",
       "      <th>Best C</th>\n",
       "      <th>LogReg Error</th>\n",
       "      <th>Baseline Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>100</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>100</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>100</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>100</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Best k  KNN Error  Best C  LogReg Error  Baseline Error\n",
       "0     1       9   0.266667     100      0.366667        0.333333\n",
       "1     2       9   0.266667       1      0.366667        0.333333\n",
       "2     3       9   0.400000       1      0.300000        0.333333\n",
       "3     4       1   0.433333     100      0.233333        0.333333\n",
       "4     5       5   0.333333     100      0.266667        0.333333\n",
       "5     6       7   0.333333     100      0.366667        0.333333\n",
       "6     7       9   0.233333       1      0.033333        0.300000\n",
       "7     8       9   0.366667     100      0.200000        0.300000\n",
       "8     9       7   0.366667     100      0.233333        0.300000\n",
       "9    10       9   0.275862     100      0.206897        0.310345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "logreg_param_grid = {'C': [100, 20, 10, 2, 1]}\n",
    "knn_param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
    "\n",
    "results_table = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Baseline\n",
    "    majority_class = np.argmax(np.bincount(y_train))\n",
    "    y_pred_baseline = np.full_like(y_test, majority_class)\n",
    "    E_baseline = 1 - accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "    # Logistic Regression (inner CV for best C)\n",
    "    logreg = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "    logreg_grid = GridSearchCV(logreg, logreg_param_grid, cv=inner_cv, scoring='accuracy')\n",
    "    logreg_grid.fit(X_train, y_train)\n",
    "    best_C = logreg_grid.best_params_['C']\n",
    "    y_pred_logreg = logreg_grid.predict(X_test)\n",
    "    E_logreg = 1 - accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "    # KNN (inner CV for best k)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn_grid = GridSearchCV(knn, knn_param_grid, cv=inner_cv, scoring='accuracy')\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    best_k = knn_grid.best_params_['n_neighbors']\n",
    "    y_pred_knn = knn_grid.predict(X_test)\n",
    "    E_knn = 1 - accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "    results_table.append([fold, best_k, E_knn, best_C, E_logreg, E_baseline])\n",
    "\n",
    "# Display results as a table\n",
    "results_df = pd.DataFrame(results_table, columns=['Fold', 'Best k', 'KNN Error', 'Best C', 'LogReg Error', 'Baseline Error'])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d745d8",
   "metadata": {},
   "source": [
    "### 3. Two-Level Cross-Validation and Error Table\n",
    "We use nested cross-validation to select the best parameters and estimate test error. The outer loop splits the data for testing, and the inner loop selects the best parameter value. The error rate is computed as:\n",
    "$$ E = \\frac{\\text{Number of misclassified observations}}{N_{\\text{test}}} $$\n",
    "The results are summarized in a table similar to Table 2, showing the selected parameters and error rates for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a934f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Best k</th>\n",
       "      <th>KNN Error</th>\n",
       "      <th>Best C</th>\n",
       "      <th>LogReg Error</th>\n",
       "      <th>Baseline Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>100</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>100</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>100</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>100</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>100</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Best k  KNN Error  Best C  LogReg Error  Baseline Error\n",
       "0     1       9   0.266667     100      0.366667        0.333333\n",
       "1     2       9   0.266667       1      0.366667        0.333333\n",
       "2     3       9   0.400000       1      0.300000        0.333333\n",
       "3     4       1   0.433333     100      0.233333        0.333333\n",
       "4     5       5   0.333333     100      0.266667        0.333333\n",
       "5     6       7   0.333333     100      0.366667        0.333333\n",
       "6     7       9   0.233333       1      0.033333        0.300000\n",
       "7     8       9   0.366667     100      0.200000        0.300000\n",
       "8     9       7   0.366667     100      0.233333        0.300000\n",
       "9    10       9   0.275862     100      0.206897        0.310345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "logreg_param_grid = {'C': [100, 20, 10, 2, 1]}\n",
    "knn_param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
    "\n",
    "results_table = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Baseline\n",
    "    majority_class = np.argmax(np.bincount(y_train))\n",
    "    y_pred_baseline = np.full_like(y_test, majority_class)\n",
    "    E_baseline = 1 - accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "    # Logistic Regression (inner CV for best C)\n",
    "    logreg = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "    logreg_grid = GridSearchCV(logreg, logreg_param_grid, cv=inner_cv, scoring='accuracy')\n",
    "    logreg_grid.fit(X_train, y_train)\n",
    "    best_C = logreg_grid.best_params_['C']\n",
    "    y_pred_logreg = logreg_grid.predict(X_test)\n",
    "    E_logreg = 1 - accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "    # KNN (inner CV for best k)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn_grid = GridSearchCV(knn, knn_param_grid, cv=inner_cv, scoring='accuracy')\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    best_k = knn_grid.best_params_['n_neighbors']\n",
    "    y_pred_knn = knn_grid.predict(X_test)\n",
    "    E_knn = 1 - accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "    results_table.append([fold, best_k, E_knn, best_C, E_logreg, E_baseline])\n",
    "\n",
    "# Display results as a table\n",
    "results_df = pd.DataFrame(results_table, columns=['Fold', 'Best k', 'KNN Error', 'Best C', 'LogReg Error', 'Baseline Error'])\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
